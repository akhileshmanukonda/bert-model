{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/akhileshmanukonda/ads-assignment-3/blob/main/reasearch_ass3.ipynb",
      "authorship_tag": "ABX9TyMdV7QkGZAxqLCI+EzOdjzM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akhileshmanukonda/bert-model/blob/main/reasearch_ass3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Research and analysis of a Bert pretrained model**\n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n",
        "\n",
        "from hugging face analyzing a pretrained bert model.BERT is a very effective tool for text categorisation because of its capacity to comprehend the relationships and context inside text. Through task-specific tweaking of BERT, practitioners may take use of cutting-edge NLP capabilities to get excellent classification accuracy for text data."
      ],
      "metadata": {
        "id": "XaYKddk_VIRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "5MMIyryEr_7O",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "id": "zmqVQR4FA9j0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tC41XifeVFFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "collapsed": true,
        "id": "QcdkmMAY1n2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "here iam starts with importing libraries and writing code for some text classification tasks\n"
      ],
      "metadata": {
        "id": "fWiC8kRKEyUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "from transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from datasets import load_dataset\n",
        "\n",
        "model_name = \"bert-base-cased\"\n",
        "# Use AutoModelForSequenceClassification for text classification tasks\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "classifier(\n",
        "    [\n",
        "        \"jake broke the vase\",\n",
        "\n",
        "    ]\n",
        ")\n",
        "sequences = [\n",
        "    \"jake broke the vase\\n\\nThe vise. This is really a great idea for the Vise\\\n",
        "    I have tried to create and I'm really hoping to see it being incorporated into the Vise.\"]\n",
        "batch = tokenizer(sequences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "batch[\"labels\"] = torch.tensor([1])\n",
        "\n",
        "optimizer = AdamW(model.parameters())\n",
        "loss = model(**batch).loss\n",
        "loss.backward()\n",
        "optimizer.step()\n"
      ],
      "metadata": {
        "id": "2JZPyg2PR8HQ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = pipeline(\"text-generation\")\n",
        "generator(\"jake broke the vase\")"
      ],
      "metadata": {
        "id": "JQBbFJtCQIvl",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset\n",
        "ds = load_dataset(\"liuyanchen1015/MULTI_VALUE_mrpc_for_to\")\n",
        "print (ds)\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"liuyanchen1015/MULTI_VALUE_mrpc_for_to\")\n",
        "\n",
        "# Convert to pandas DataFrame for easier manipulation\n",
        "train_df = dataset['train'].to_pandas()\n",
        "test_df = dataset['test'].to_pandas()\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TQn3x6460r89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the training set\n",
        "print(train_df.head())\n",
        "\n",
        "# Display basic information about the training set\n",
        "print(train_df.info())\n",
        "\n",
        "# Check for missing values\n",
        "print(train_df.isnull().sum())\n"
      ],
      "metadata": {
        "id": "6ToY6nxdqvZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get descriptive statistics for the dataset\n",
        "print(train_df.describe())\n",
        "\n",
        "# Check the distribution of the labels\n",
        "print(train_df['label'].value_counts())\n"
      ],
      "metadata": {
        "id": "e3Z6u7SIqzfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the distribution of the labels\n",
        "sns.countplot(x='label', data=train_df)\n",
        "plt.title('Distribution of Labels')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "h8MoKJZ5q29E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the length of each sentence\n",
        "train_df['sentence1_length'] = train_df['sentence1'].apply(len)\n",
        "train_df['sentence2_length'] = train_df['sentence2'].apply(len)\n",
        "\n",
        "# Plot the distribution of sentence lengths\n",
        "sns.histplot(train_df['sentence1_length'], kde=True, color='blue', label='Sentence 1 Length')\n",
        "sns.histplot(train_df['sentence2_length'], kde=True, color='green', label='Sentence 2 Length')\n",
        "plt.legend()\n",
        "plt.title('Distribution of Sentence Lengths')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EgmmBqOuq8Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicate rows\n",
        "duplicates = train_df.duplicated(subset=['sentence1', 'sentence2']).sum()\n",
        "print(f\"Number of duplicate sentence pairs: {duplicates}\")\n"
      ],
      "metadata": {
        "id": "cUldvWeRrDHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "# Generate a word cloud for the first sentences\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(train_df['sentence1']))\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud for Sentence 1')\n",
        "plt.show()\n",
        "\n",
        "# Generate a word cloud for the second sentences\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(train_df['sentence2']))\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud for Sentence 2')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "uxHnO2i2rGE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = ds[\"train\"]\n",
        "train_set[0]\n",
        "\n",
        "\n",
        "train_set.features"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RpObOVsDKI2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "# Access the correct columns within the train_set Dataset\n",
        "tokenized_sentences_1 = tokenizer(train_set[\"sentence1\"])\n",
        "tokenized_sentences_2 = tokenizer(train_set[\"sentence2\"])"
      ],
      "metadata": {
        "id": "RFYvJaN-KkK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer('Around 0335 GMT , Tab shares was up 19 cents , or 4.4 % , at A $ 4.56 , having earlier set a record high of A $ 4.57 .',\n",
        " 'Tab shares jumped 20 cents , or 4.6 % , to set a record closing high at A $ 4.57 .')\n",
        "inputs"
      ],
      "metadata": {
        "collapsed": true,
        "id": "StT30KDYLuZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"])"
      ],
      "metadata": {
        "id": "M1CQaiWYMRM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_dataset = tokenizer(\n",
        "    train_set[\"sentence1\"],\n",
        "    train_set[\"sentence2\"],\n",
        "    padding=True,\n",
        "    truncation=True,\n",
        ")\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZlcripGuNzcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_datasets = train_set.map(tokenize_function, batched=True)\n",
        "tokenized_datasets"
      ],
      "metadata": {
        "id": "NKmyE02dNV8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.init(project=\"reasearch_ass3\")"
      ],
      "metadata": {
        "id": "1I3Xl-TRk5uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\"test-trainer\")\n",
        "\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
      ],
      "metadata": {
        "id": "Tg8tTKxFOxKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=3e-5)"
      ],
      "metadata": {
        "id": "Z-WOYy4aiLeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'train_set' is your entire dataset, split it first\n",
        "from datasets import DatasetDict\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"weighted\")\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
        "\n",
        "\n",
        "\n",
        "# Adjust split ratio as needed\n",
        "train_testvalid = train_set.train_test_split(test_size=0.2)\n",
        "train_valid = train_testvalid['test'].train_test_split(test_size=0.5)\n",
        "\n",
        "# Create a DatasetDict\n",
        "tokenized_datasets = DatasetDict({\n",
        "    'train': train_testvalid['train'],\n",
        "    'validation': train_valid['test'],\n",
        "    'test': train_valid['train']\n",
        "})\n",
        "\n",
        "# Adjust TrainingArguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./model_output\",\n",
        "    run_name=\"unique_run_name\",\n",
        "    save_strategy= \"epoch\",\n",
        "    logging_dir=\"./logs\",\n",
        "    num_train_epochs= 5,\n",
        "    logging_steps=50,\n",
        "    learning_rate=2e-5,\n",
        "    #report_to=\"wandb\",\n",
        "    )\n",
        "# Apply tokenization\n",
        "tokenized_datasets = tokenized_datasets.map(tokenize_function, batched=True)\n",
        "from transformers import Trainer\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "ZXrZPh3_PCZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "o6U4qfkkPqqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = trainer.predict(tokenized_datasets[\"validation\"])\n",
        "print(predictions.predictions.shape, predictions.label_ids.shape)"
      ],
      "metadata": {
        "id": "pgSoCJfAKj7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "preds = np.argmax(predictions.predictions, axis=-1)"
      ],
      "metadata": {
        "id": "6U-04_2wMTAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install evaluate"
      ],
      "metadata": {
        "id": "yDkSk7VjMkpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"f1\")\n",
        "metric.compute(predictions=preds, references=predictions.label_ids)\n",
        "print(metric)"
      ],
      "metadata": {
        "id": "gy-kRWA8MXZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming trainer.state.log_history contains the training history\n",
        "train_loss = [log['loss'] for log in trainer.state.log_history if 'loss' in log]\n",
        "# Extract validation loss if available (e.g., using 'eval_loss')\n",
        "validation_loss = [log['eval_loss'] for log in trainer.state.log_history if 'eval_loss' in log]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_loss, label='Train Loss')\n",
        "plt.plot(validation_loss, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch/Step')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0h7Jj8oCxXCX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}